{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/mariumnour/Project-1/blob/main/finalThesis.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "5p8w83lEbnMf",
        "outputId": "f015eeb9-cf02-43f4-a0c2-b3d98b158bc7"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Drive already mounted at /content/drive; to attempt to forcibly remount, call drive.mount(\"/content/drive\", force_remount=True).\n"
          ]
        }
      ],
      "source": [
        "# Mount Google Drive to access the CSV files\n",
        "from google.colab import drive\n",
        "drive.mount('/content/drive')\n",
        "\n",
        "# Import necessary libraries\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "# Define the path of the folder containing the CSV files on Google Drive\n",
        "folder_path = '/content/drive/MyDrive/DataSets'\n",
        "\n",
        "# Define the list of CSV files to load\n",
        "file_names = ['02-14-2018.csv',\n",
        "              '02-15-2018.csv',\n",
        "              '02-16-2018.csv',\n",
        "              '02-20-2018.csv',\n",
        "              '02-21-2018.csv',\n",
        "              '02-22-2018.csv',\n",
        "              '02-23-2018.csv',\n",
        "              '02-28-2018.csv',\n",
        "              '03-01-2018.csv',\n",
        "              '03-02-2018.csv']\n",
        "\n",
        "# Load each CSV file into a dataframe, clean it, and split it into train and test sets\n",
        "train_dfs = []\n",
        "test_dfs = []\n",
        "for file_name in file_names:\n",
        "    file_path = f'{folder_path}/{file_name}'\n",
        "    df = pd.read_csv(file_path, low_memory=False)\n",
        "    \n",
        "    # Remove rows with missing or invalid values\n",
        "    df = df.replace([np.inf, -np.inf], np.nan)\n",
        "    df = df.dropna()\n",
        "    \n",
        "    # Drop columns with constant or near-constant values\n",
        "    constant_cols = [col for col in df.columns if df[col].nunique() <= 1]\n",
        "    df = df.drop(constant_cols, axis=1)\n",
        "    \n",
        "    # Drop rows with duplicated values\n",
        "    df = df.drop_duplicates()\n",
        "\n",
        "     # Delete half of the dataframe\n",
        "    df = df.sample(frac=0.5, random_state=42)\n",
        "    \n",
        "    # Convert categorical features to numerical features\n",
        "    cat_cols = [col for col in df.columns if df[col].dtype == 'object']\n",
        "    for col in cat_cols:\n",
        "        df[col] = pd.factorize(df[col])[0]\n",
        "    \n",
        "    # Split the dataframe into train and test sets\n",
        "    train_df, test_df = train_test_split(df, test_size=0.2, random_state=42)\n",
        "    \n",
        "    train_dfs.append(train_df)\n",
        "    test_dfs.append(test_df)\n",
        "\n",
        "# Concatenate all the train and test dataframes\n",
        "train_df = pd.concat(train_dfs, axis=0)\n",
        "test_df = pd.concat(test_dfs, axis=0)\n",
        "\n",
        "# Save the new train and test dataframes to CSV files in your Google Drive\n",
        "#train_df.to_csv('/content/drive/MyDrive/path/to/new_train_file.csv', index=False)\n",
        "#test_df.to_csv('/content/drive/MyDrive/path/to/new_test_file.csv', index=False)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "pJYKRXJBcCV5"
      },
      "outputs": [],
      "source": [
        "# Create a dictionary to map each attack type to its category\n",
        "attack_category = {\n",
        "    'DDoS': 'attack',\n",
        "    'DoS': 'attack',\n",
        "    'Web Attack - Brute Force': 'attack',\n",
        "    'Bot': 'attack',\n",
        "    'Infiltration': 'attack',\n",
        "    'Web Attack - XSS': 'attack',\n",
        "    'Web Attack - Sql Injection': 'attack',\n",
        "    'PortScan': 'attack',\n",
        "    'Benign': 'benign'\n",
        "}\n",
        "\n",
        "# Create a new column in the dataframe to store the attack category\n",
        "train_df['attack_category'] = train_df['Label'].map(attack_category)\n",
        "test_df['attack_category'] = test_df['Label'].map(attack_category)\n"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Drop the columns from the train and test dataframes\n",
        "train_df = train_df.drop([\"Timestamp\"], axis=1)\n",
        "test_df = test_df.drop([\"Timestamp\"], axis=1)\n"
      ],
      "metadata": {
        "id": "TUbmzokpcXtl"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_train = train_df.loc[:, ['Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'Fwd Pkt Len Max', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Std', 'Bwd Pkt Len Max', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Std', 'Flow Byts/s', 'Flow Pkts/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Fwd Header Len', 'Bwd Header Len', 'Fwd Pkts/s', 'Bwd Pkts/s', 'Pkt Len Max', 'Pkt Len Mean', 'Pkt Len Std', 'Pkt Len Var', 'FIN Flag Cnt', 'SYN Flag Cnt', 'RST Flag Cnt', 'PSH Flag Cnt', 'ACK Flag Cnt', 'URG Flag Cnt', 'CWE Flag Count', 'ECE Flag Cnt', 'Down/Up Ratio', 'Init Fwd Win Byts', 'Init Bwd Win Byts', 'Fwd Seg Size Avg', 'Bwd Seg Size Avg', 'Fwd Byts/b Avg', 'Fwd Pkts/b Avg', 'Fwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Pkts/b Avg', 'Bwd Blk Rate Avg', 'Subflow Fwd Pkts', 'Subflow Fwd Byts', 'Subflow Bwd Pkts', 'Subflow Bwd Byts', 'Init Fwd Win Byts', 'Init Bwd Win Byts', 'Fwd Act Data Pkts', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min']]\n",
        "y_train = train_df['Label']\n",
        "X_test = test_df.loc[:, ['Flow Duration', 'Tot Fwd Pkts', 'Tot Bwd Pkts', 'Fwd Pkt Len Max', 'Fwd Pkt Len Mean', 'Fwd Pkt Len Std', 'Bwd Pkt Len Max', 'Bwd Pkt Len Mean', 'Bwd Pkt Len Std', 'Flow Byts/s', 'Flow Pkts/s', 'Flow IAT Mean', 'Flow IAT Std', 'Flow IAT Max', 'Fwd IAT Mean', 'Fwd IAT Std', 'Fwd IAT Max', 'Bwd IAT Mean', 'Bwd IAT Std', 'Bwd IAT Max', 'Fwd Header Len', 'Bwd Header Len', 'Fwd Pkts/s', 'Bwd Pkts/s', 'Pkt Len Max', 'Pkt Len Mean', 'Pkt Len Std', 'Pkt Len Var', 'FIN Flag Cnt', 'SYN Flag Cnt', 'RST Flag Cnt', 'PSH Flag Cnt', 'ACK Flag Cnt', 'URG Flag Cnt', 'CWE Flag Count', 'ECE Flag Cnt', 'Down/Up Ratio', 'Init Fwd Win Byts', 'Init Bwd Win Byts', 'Fwd Seg Size Avg', 'Bwd Seg Size Avg', 'Fwd Byts/b Avg', 'Fwd Pkts/b Avg', 'Fwd Blk Rate Avg', 'Bwd Byts/b Avg', 'Bwd Pkts/b Avg', 'Bwd Blk Rate Avg', 'Subflow Fwd Pkts', 'Subflow Fwd Byts', 'Subflow Bwd Pkts', 'Subflow Bwd Byts', 'Init Fwd Win Byts', 'Init Bwd Win Byts', 'Fwd Act Data Pkts', 'Fwd Seg Size Min', 'Active Mean', 'Active Std', 'Active Max', 'Active Min', 'Idle Mean', 'Idle Std', 'Idle Max', 'Idle Min']]\n",
        "y_test = test_df['Label']"
      ],
      "metadata": {
        "id": "efFHLpPJgKYL"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "new_df = df.dropna()\n"
      ],
      "metadata": {
        "id": "4tSdYwLxo9L3"
      },
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Import necessary libraries\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define the input and target variables\n",
        "X = new_df.drop(['Label'], axis=1)\n",
        "y = new_df['Label']\n",
        "\n",
        "# Split the data into training and testing sets\n",
        "#X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Create a random forest classifier\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Train the classifier on the training data\n",
        "rf.fit(X_train, y_train)\n",
        "\n",
        "# Test the classifier on the testing data\n",
        "y_pred = rf.predict(X_test)\n",
        "\n",
        "# Evaluate the accuracy of the classifier\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(f'Accuracy: {accuracy:.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GkaPo5kcpFg5",
        "outputId": "07dab9bf-d4a6-42a3-d7a9-c18ef7239eb5"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy: 1.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "\n",
        "# Create a random forest classifier\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Evaluate the model using 10-fold cross-validation\n",
        "scores = cross_val_score(rf, X, y, cv=10)\n",
        "\n",
        "# Print the mean and standard deviation of the cross-validation scores\n",
        "print(f'Mean cross-validation score: {scores.mean():.2f}')\n",
        "print(f'Standard deviation of cross-validation scores: {scores.std():.2f}')\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7zvd-e1qqJ8",
        "outputId": "c5b3c577-136b-4d4d-b8bf-ec2a1599fb32"
      },
      "execution_count": 10,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Mean cross-validation score: 1.00\n",
            "Standard deviation of cross-validation scores: 0.00\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Define the input and target variables\n",
        "X = new_df.drop(['Label'], axis=1)\n",
        "y = new_df['Label']\n",
        "\n",
        "# Create a stratified 10-fold object\n",
        "skf = StratifiedKFold(n_splits=10, shuffle=True, random_state=42)\n",
        "\n",
        "# Create a random forest classifier\n",
        "rf = RandomForestClassifier(n_estimators=100, random_state=42)\n",
        "\n",
        "# Initialize an empty list to store the accuracy scores\n",
        "scores = []\n",
        "\n",
        "# Loop through the folds and fit the model\n",
        "for train_idx, test_idx in skf.split(X, y):\n",
        "    X_train, y_train = X.iloc[train_idx], y.iloc[train_idx]\n",
        "    X_test, y_test = X.iloc[test_idx], y.iloc[test_idx]\n",
        "    rf.fit(X_train, y_train)\n",
        "    y_pred = rf.predict(X_test)\n",
        "    score = accuracy_score(y_test, y_pred)\n",
        "    scores.append(score)\n",
        "\n",
        "# Calculate and print the mean and standard deviation of the scores\n",
        "mean_score = sum(scores) / len(scores)\n",
        "std_score = np.std(scores)\n",
        "print(f'Mean cross-validation score: {mean_score:.2f}')\n",
        "print(f'Standard deviation of cross-validation scores: {std_score:.2f}')\n"
      ],
      "metadata": {
        "id": "8f-Jf7QTv9G6"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": [],
      "authorship_tag": "ABX9TyPg4mNOqfse32A+RwWDzGDB",
      "include_colab_link": true
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}